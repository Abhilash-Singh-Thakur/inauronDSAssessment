{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241d601b",
   "metadata": {},
   "source": [
    "1. Setting up a Kafka Producer:\n",
    "   a) Write a Python program to create a Kafka producer.\n",
    "   b) Configure the producer to connect to a Kafka cluster.\n",
    "   c) Implement logic to send messages to a Kafka topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f450b3e3",
   "metadata": {},
   "source": [
    "a) Write a Python program to create a Kafka producer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "def kafka_producer(bootstrap_servers):\n",
    "    # Create a Kafka producer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers\n",
    "    }\n",
    "\n",
    "    # Create the Kafka producer\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    return producer\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Create a Kafka producer\n",
    "producer = kafka_producer(bootstrap_servers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e8d9d",
   "metadata": {},
   "source": [
    "b) Configure the producer to connect to a Kafka cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623aca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "def kafka_producer(bootstrap_servers):\n",
    "    # Create a Kafka producer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers\n",
    "    }\n",
    "\n",
    "    # Create the Kafka producer\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    return producer\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'kafka1:9092,kafka2:9092,kafka3:9092'\n",
    "\n",
    "# Create a Kafka producer\n",
    "producer = kafka_producer(bootstrap_servers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b99314",
   "metadata": {},
   "source": [
    "c) Implement logic to send messages to a Kafka topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab479836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(producer, topic, message):\n",
    "    # Produce the message to the specified Kafka topic\n",
    "    producer.produce(topic, message)\n",
    "\n",
    "    # Flush the producer to ensure the message is sent\n",
    "    producer.flush()\n",
    "\n",
    "# Specify the Kafka topic to send messages to\n",
    "topic = 'my_topic'\n",
    "\n",
    "# Send a message to the Kafka topic\n",
    "message = 'Hello, Kafka!'\n",
    "send_message(producer, topic, message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d02fb8",
   "metadata": {},
   "source": [
    "2. Setting up a Kafka Consumer:\n",
    "   a) Write a Python program to create a Kafka consumer.\n",
    "   b) Configure the consumer to connect to a Kafka cluster.\n",
    "   c) Implement logic to consume messages from a Kafka topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cc186",
   "metadata": {},
   "source": [
    "a) Write a Python program to create a Kafka consumer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "def kafka_consumer(bootstrap_servers, group_id):\n",
    "    # Create a Kafka consumer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers,\n",
    "        'group.id': group_id,\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "\n",
    "    # Create the Kafka consumer\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    return consumer\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the consumer group ID\n",
    "group_id = 'my_consumer_group'\n",
    "\n",
    "# Create a Kafka consumer\n",
    "consumer = kafka_consumer(bootstrap_servers, group_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0823c3",
   "metadata": {},
   "source": [
    "b) Configure the consumer to connect to a Kafka cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d4382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "def kafka_consumer(bootstrap_servers, group_id):\n",
    "    # Create a Kafka consumer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers,\n",
    "        'group.id': group_id,\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "\n",
    "    # Create the Kafka consumer\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    return consumer\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'kafka1:9092,kafka2:9092,kafka3:9092'\n",
    "\n",
    "# Specify the consumer group ID\n",
    "group_id = 'my_consumer_group'\n",
    "\n",
    "# Create a Kafka consumer\n",
    "consumer = kafka_consumer(bootstrap_servers, group_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f3fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "c) Implement logic to consume messages from a Kafka topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_messages(consumer, topic):\n",
    "    # Subscribe to the specified Kafka topic\n",
    "    consumer.subscribe([topic])\n",
    "\n",
    "    # Continuously consume messages from the topic\n",
    "    while True:\n",
    "        # Poll for new messages\n",
    "        message = consumer.poll(1.0)\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "        if message.error():\n",
    "            print(\"Consumer error:\", message.error())\n",
    "            continue\n",
    "\n",
    "        # Process the consumed message\n",
    "        print(\"Received message:\", message.value().decode('utf-8'))\n",
    "\n",
    "        # Commit the consumed message offset\n",
    "        consumer.commit(message)\n",
    "\n",
    "# Specify the Kafka topic to consume messages from\n",
    "topic = 'my_topic'\n",
    "\n",
    "# Consume messages from the Kafka topic\n",
    "consume_messages(consumer, topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93173353",
   "metadata": {},
   "source": [
    "3. Creating and Managing Kafka Topics:\n",
    "   a) Write a Python program to create a new Kafka topic.\n",
    "   b) Implement functionality to list existing topics.\n",
    "   c) Develop logic to delete an existing Kafka topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80637f00",
   "metadata": {},
   "source": [
    "   a) Write a Python program to create a new Kafka topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3debc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "def create_topic(bootstrap_servers, topic_name, num_partitions, replication_factor):\n",
    "    # Create an AdminClient with the specified bootstrap servers\n",
    "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
    "\n",
    "    # Create a NewTopic instance with the desired topic configurations\n",
    "    topic = NewTopic(topic_name, num_partitions, replication_factor)\n",
    "\n",
    "    # Create the topic using the AdminClient\n",
    "    admin_client.create_topics([topic])\n",
    "\n",
    "    print(f\"Topic '{topic_name}' created successfully.\")\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the topic details\n",
    "topic_name = 'my_topic'\n",
    "num_partitions = 3\n",
    "replication_factor = 1\n",
    "\n",
    "# Create a new Kafka topic\n",
    "create_topic(bootstrap_servers, topic_name, num_partitions, replication_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527768f",
   "metadata": {},
   "source": [
    "   b) Implement functionality to list existing topics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b91d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "def create_topic(bootstrap_servers, topic_name, num_partitions, replication_factor):\n",
    "    # Create an AdminClient with the specified bootstrap servers\n",
    "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
    "\n",
    "    # Create a NewTopic instance with the desired topic configurations\n",
    "    topic = NewTopic(topic_name, num_partitions, replication_factor)\n",
    "\n",
    "    # Create the topic using the AdminClient\n",
    "    admin_client.create_topics([topic])\n",
    "\n",
    "    print(f\"Topic '{topic_name}' created successfully.\")\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the topic details\n",
    "topic_name = 'my_topic'\n",
    "num_partitions = 3\n",
    "replication_factor = 1\n",
    "\n",
    "# Create a new Kafka topic\n",
    "create_topic(bootstrap_servers, topic_name, num_partitions, replication_factor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2967dc60",
   "metadata": {},
   "source": [
    "   c) Develop logic to delete an existing Kafka topic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80abce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_topic(bootstrap_servers, topic_name):\n",
    "    # Create an AdminClient with the specified bootstrap servers\n",
    "    admin_client = AdminClient({'bootstrap.servers': bootstrap_servers})\n",
    "\n",
    "    # Delete the specified topic using the AdminClient\n",
    "    admin_client.delete_topics([topic_name])\n",
    "\n",
    "    print(f\"Topic '{topic_name}' deleted successfully.\")\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the name of the topic to delete\n",
    "topic_name = 'my_topic'\n",
    "\n",
    "# Delete the Kafka topic\n",
    "delete_topic(bootstrap_servers, topic_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e5793",
   "metadata": {},
   "source": [
    "4. Producing and Consuming Messages:\n",
    "   a) Write a Python program to produce messages to a Kafka topic.\n",
    "   b) Implement logic to consume messages from the same Kafka topic.\n",
    "   c) Test the end-to-end flow of message production and consumption.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a47ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "def produce_messages(bootstrap_servers, topic, messages):\n",
    "    # Create a Kafka producer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers\n",
    "    }\n",
    "\n",
    "    # Create the Kafka producer\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    # Produce messages to the Kafka topic\n",
    "    for message in messages:\n",
    "        producer.produce(topic, value=message)\n",
    "        producer.flush()\n",
    "\n",
    "    print(\"Messages produced successfully.\")\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the Kafka topic to produce messages to\n",
    "topic = 'my_topic'\n",
    "\n",
    "# Specify the messages to produce\n",
    "messages = [\n",
    "    'Hello, Kafka!',\n",
    "    'How are you?',\n",
    "    'Testing Kafka producer'\n",
    "]\n",
    "\n",
    "# Produce messages to the Kafka topic\n",
    "produce_messages(bootstrap_servers, topic, messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851db48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c47af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "def consume_messages(bootstrap_servers, topic):\n",
    "    # Create a Kafka consumer configuration\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers,\n",
    "        'group.id': 'my_consumer_group',\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "\n",
    "    # Create the Kafka consumer\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    # Subscribe to the Kafka topic\n",
    "    consumer.subscribe([topic])\n",
    "\n",
    "    # Consume messages from the Kafka topic\n",
    "    while True:\n",
    "        message = consumer.poll(1.0)\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "        if message.error():\n",
    "            print(\"Consumer error:\", message.error())\n",
    "            continue\n",
    "\n",
    "        # Process the consumed message\n",
    "        print(\"Received message:\", message.value().decode('utf-8'))\n",
    "\n",
    "        # Commit the consumed message offset\n",
    "        consumer.commit()\n",
    "\n",
    "# Specify the bootstrap servers of the Kafka cluster\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "\n",
    "# Specify the Kafka topic to consume messages from\n",
    "topic = 'my_topic'\n",
    "\n",
    "# Consume messages from the Kafka topic\n",
    "consume_messages(bootstrap_servers, topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f869d2",
   "metadata": {},
   "source": [
    "To test the end-to-end flow of message production and consumption in Kafka using Python, you need to run both the message producer and consumer programs simultaneously. Here's an example of how you can test the end-to-end flow:\n",
    "\n",
    "Open two separate terminal windows or command prompts.\n",
    "\n",
    "In the first terminal, run the consumer program to start consuming messages from the Kafka topic:\n",
    "\n",
    "python consumer.py\n",
    "\n",
    "In the second terminal, run the producer program to start producing messages to the Kafka topic:\n",
    "\n",
    "python producer.py\n",
    "\n",
    "The producer program will send the messages to the Kafka topic, and the consumer program will consume and print them.\n",
    "\n",
    "Observe the output in the consumer terminal. You should see the received messages printed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# producer.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef27c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "\n",
    "def produce_messages(bootstrap_servers, topic, messages):\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers\n",
    "    }\n",
    "    producer = Producer(conf)\n",
    "\n",
    "    for message in messages:\n",
    "        producer.produce(topic, value=message)\n",
    "        producer.flush()\n",
    "\n",
    "    print(\"Messages produced successfully.\")\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'my_topic'\n",
    "messages = [\n",
    "    'Hello, Kafka!',\n",
    "    'How are you?',\n",
    "    'Testing Kafka producer'\n",
    "]\n",
    "produce_messages(bootstrap_servers, topic, messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e332e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "def consume_messages(bootstrap_servers, topic):\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers,\n",
    "        'group.id': 'my_consumer_group',\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "    consumer = Consumer(conf)\n",
    "\n",
    "    consumer.subscribe([topic])\n",
    "\n",
    "    while True:\n",
    "        message = consumer.poll(1.0)\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "        if message.error():\n",
    "            print(\"Consumer error:\", message.error())\n",
    "            continue\n",
    "\n",
    "        print(\"Received message:\", message.value().decode('utf-8'))\n",
    "\n",
    "        consumer.commit()\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "topic = 'my_topic'\n",
    "consume_messages(bootstrap_servers, topic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd99992",
   "metadata": {},
   "source": [
    "5. Working with Kafka Consumer Groups:\n",
    "   a) Write a Python program to create a Kafka consumer within a consumer group.\n",
    "   b) Implement logic to handle messages consumed by different consumers within the same group.\n",
    "   c) Observe the behavior of consumer group rebalancing when adding or removing consumers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772b623",
   "metadata": {},
   "source": [
    "a) Write a Python program to create a Kafka consumer within a consumer group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06535d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consume_messages(consumer, topic):\n",
    "    consumer.subscribe([topic])\n",
    "    while True:\n",
    "        message = consumer.poll(1.0)\n",
    "\n",
    "        if message is None:\n",
    "            continue\n",
    "        if message.error():\n",
    "            print(\"Consumer error:\", message.error())\n",
    "            continue\n",
    "\n",
    "        print(f\"Consumer within group {consumer.conf['group.id']} received message:\", message.value().decode('utf-8'))\n",
    "\n",
    "        consumer.commit()\n",
    "\n",
    "topic = 'my_topic'\n",
    "consume_messages(consumer, topic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01336e4",
   "metadata": {},
   "source": [
    "b) Implement logic to handle messages consumed by different consumers within the same group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058406d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "\n",
    "def create_consumer(bootstrap_servers, group_id):\n",
    "    conf = {\n",
    "        'bootstrap.servers': bootstrap_servers,\n",
    "        'group.id': group_id,\n",
    "        'auto.offset.reset': 'earliest'\n",
    "    }\n",
    "    consumer = Consumer(conf)\n",
    "    return consumer\n",
    "\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "group_id = 'my_consumer_group'\n",
    "consumer = create_consumer(bootstrap_servers, group_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
